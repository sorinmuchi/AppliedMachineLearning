import tensorflow as tf
import keras
import numpy as np
import math
from cleverhans.utils_mnist import data_mnist
from cleverhans.utils import cnn_model, other_classes
from cleverhans.utils_tf import model_train, model_eval, batch_eval
from cleverhans.attacks_tf import jacobian_graph
from cleverhans.attacks import jsma, fgsm
from six.moves import xrange
from pcp import *


from tensorflow.python.platform import flags
FLAGS = flags.FLAGS

flags.DEFINE_integer('nb_classes', 10, 'Number of classification classes')

"""
To run from shell, run below command first:
(GOOGLE CLOUD)
cd /home/cmazzaanthony/Kal-El
source activate env
export PYTHONPATH="../cleverhans":$PYTHONPATH

(MAC)
export PYTHONPATH="../cleverhans":$PYTHONPATH

Libraries are from Cleverhans here: https://github.com/openai/cleverhans
"""

class AdversarialCNNJSMA:

    def __init__(self, train_size=None, test_size=None):
        self.session = self.set_up_sess()
        self.X_train, self.Y_train, self.X_test, self.Y_test = self.retrieve_mnist_dataset(train_size, test_size)
        self.x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))
        self.y = tf.placeholder(tf.float32, shape=(None, 10))
        self.epochs = 10
        self.batch_size = 128
        self.learning_rate = 0.1
        self.classes = 10 # 10 numbers in MNIST dataset
        self.img_rows = 28
        self.img_cols = 28
        self.channels = 1
        self.attacK_samples = 20

    def set_up_sess(self):
        if keras.backend.image_dim_ordering() != 'tf':
            keras.backend.set_image_dim_ordering('tf')

        sess = tf.Session()
        keras.backend.set_session(sess)
        return sess

    def retrieve_mnist_dataset(self, training_size, test_size):
        X_train, Y_train, X_test, Y_test = data_mnist()

        return X_train[:training_size, :, :, :], \
               Y_train[:training_size, :], \
               X_test[:test_size, :, :, :], \
               Y_test[:test_size, :]

    def train(self):
        model = cnn_model()
        predictions = model(self.x)

        train_params = {
            'nb_epochs': self.epochs,
            'batch_size': self.batch_size,
            'learning_rate': self.learning_rate
        }

        model_train(self.session, self.x, self.y, predictions,
                    self.X_train, self.Y_train,
                    args=train_params)

        # Evaluate the accuracy of the MNIST model on legitimate test examples
        eval_params = {'batch_size': self.batch_size}
        accuracy = model_eval(self.session, self.x, self.y, predictions,
                              self.X_test, self.Y_test, args=eval_params)

        print('Test accuracy on legitimate test examples: {0}'.format(accuracy))

        return predictions

    def validate_with_adversarial_fgsm(self):
        # First train with adversarial examples generated by JSMA method
        model = cnn_model()
        predictions = model(self.x)
        eval_params = {'batch_size': self.batch_size}

        # Load JSMA adversarial examples
        X_jsma = np.load("src/jsma/X_adv_out_jsma.npy")
        Y_jsma = np.load("src/jsma/Y_adv_out_jsma.npy")
        print("Loaded {0} JSMA adversarial examples to train".format(X_jsma.shape[0]))

        train_params = {
            'nb_epochs': self.epochs,
            'batch_size': self.batch_size,
            'learning_rate': self.learning_rate
        }

        model_train(self.session, self.x, self.y, predictions,
                    X_jsma, Y_jsma,
                    args=train_params)

        # accuracy = model_eval(self.session, self.x, self.y, predictions,
        #                       self.X_test, self.Y_test, args=eval_params)

        # print('Test accuracy on legitimate test examples when trained with JSMA adversarial examples: {0}'.format(accuracy))

        # model_adv = cnn_model()
        # predictions_adv = model_adv(self.x)

        # load FGSM adversarial examples
        X_fgsm = np.load("src/fgsm/X_adv_out_fgsm.npy")[:1000, :, :, :]
        Y_fgsm = np.load("src/fgsm/Y_adv_out_fgsm.npy")[:1000, :]
        print("Loaded {0} adversarial examples to train".format(X_fgsm.shape[0]))

        accuracy = model_eval(self.session, self.x, self.y, predictions,
                              X_fgsm, Y_fgsm, args=eval_params)

        print('Test accuracy on FGSM adversarial examples: {0}'.format(accuracy))

    def create_adversarial_examples_jsma(self, predictions, source_samples=10000):

        results = np.zeros((self.classes, source_samples), dtype='i')

        # Define the TF graph for the model's Jacobian
        grads = jacobian_graph(predictions, self.x, self.classes)

        perturbations = np.zeros((self.classes, source_samples),
                                 dtype='f')

        adv_x_list = []
        adv_y_list = []

        # Loop over the samples we want to perturb into adversarial examples
        for sample_ind in xrange(0, source_samples):
            # We want to find an adversarial example for each possible target class
            # (i.e. all classes that differ from the label given in the dataset)
            current_class = int(np.argmax(self.Y_test[sample_ind]))
            target_classes = other_classes(self.classes, current_class)

            # For the grid visualization, keep original images along the diagonal
            # grid_viz_data[current_class, current_class, :, :, :] = np.reshape(
            #     self.X_test[sample_ind:(sample_ind + 1)],
            #     (self.img_rows, self.img_cols, self.channels))

            # Loop over all target classes
            for target in target_classes:
                print('--------------------------------------')
                print('Creating adv. example for target class ' + str(target))

                # This call runs the Jacobian-based saliency map approach
                adv_x, res, percent_perturb = jsma(self.session, self.x, predictions, grads,
                                                   self.X_test[sample_ind:
                                                   (sample_ind + 1)],
                                                   target, theta=1, gamma=0.1,
                                                   increase=True, back='tf',
                                                   clip_min=0, clip_max=1)

                results[target, sample_ind] = res
                perturbations[target, sample_ind] = percent_perturb
                adv_x_list.append(adv_x)

            adv_y_list.append(self.Y_test[sample_ind])

        print("Created {0} adversarial examples".format(len(adv_x_list)))
        X_adv_out = np.empty([1, 28, 28, 1])
        Y_adv_out = np.empty([1, 10])
        for adv_x in adv_x_list:
            X_adv_out = np.append(X_adv_out, adv_x, axis=0)

        for adv_y in adv_y_list:
            Y_adv_out = np.append(Y_adv_out, adv_y.reshape(1,10), axis=0)

        np.save('src/jsma/X_adv_out_jsma', X_adv_out)
        np.save('src/jsma/Y_adv_out_jsma', Y_adv_out)

        return results, perturbations, adv_x_list, adv_y_list

    def train_with_adversarial(self):
        """
        Important function where most of the testing was done.
        :return:
        """

        # Append adv examples to training set
        # for adv_x, adv_y in zip(adv_x_list, adv_y_list):
        #     self.X_train = np.append(self.X_train, adv_x, axis=0)
        #     self.Y_train = np.append(self.Y_train, adv_y.reshape(1,10), axis=0)

        # X_jsma = np.load("jsma/X_adv_out_jsma.npy")
        # Y_jsma = np.load("jsma/Y_adv_out_jsma.npy")

        X_jsma = np.load("jsma/x_jsma.npy")
        Y_jsma = np.load("jsma/y_jsma.npy")

        X_fgsm = np.load("fgsm/X2_adv_out_fgsm.npy")
        Y_fgsm = np.load("fgsm/Y2_adv_out_fgsm.npy")

        X_pca = np.load('pcp_x_out.npy')
        X_pca = X_pca.reshape(1001, 28, 28, 1)

        X_pca_jsma = np.load('pcp_x_out_jsma.npy')
        X_pca_jsma = X_pca_jsma.reshape(1002, 28, 28, 1)

        X_pca_fgsm = np.load('pcp_x_out_fgsm.npy')
        X_pca_fgsm = X_pca_fgsm.reshape(1001, 28, 28, 1)

        X_train = np.append(X_jsma[:9000, :, :, :], self.X_train[:1000, :, :, :], axis=0)
        Y_train = np.append(Y_jsma[:9000, :], self.Y_train[:1000, :], axis=0)

        # X_adv_out = np.empty([1, 28, 28])
        # for x in X_fgsm[:1000, :, :, :]:
        #     # S,L = robust_pca(x[:,:,0])
        #     L, S, (u, s, v) = pcp(x[:,:,0])
        #     X_adv_out = np.append(X_adv_out, L.reshape(1,28,28), axis=0)

        # L_X, S_X = robust_pca(self.X_train[:1000, :, :, :])
        # L_Y, S_Y = robust_pca(self.Y_train[:1000, :])
        # X_train, X_test, y_train, y_test = train_test_split(X_jsma, Y_jsma, test_size = 0.33, random_state = 42)

        # print("Loaded JSMA {0} adversarial examples to train".format(X_train.shape[0]))
        # print("Loaded JSMA {0} adversarial examples to test".format(X_test.shape[0]))

        adv_model = cnn_model()
        predictions = adv_model(self.x)

        train_params = {
            'nb_epochs': self.epochs,
            'batch_size': self.batch_size,
            'learning_rate': self.learning_rate
        }

        model_train(self.session, self.x, self.y, predictions,
                    self.X_train[:10000,:,:,:], self.Y_train[:10000,:],
                    args=train_params)

        eval_params = {'batch_size': self.batch_size}
        accuracy = model_eval(self.session, self.x, self.y, predictions,
                              X_jsma, Y_jsma, args=eval_params)

        print('Test accuracy with adversarial training: {0}'.format(accuracy))
        print('The number of adversarial examples in training set: {0}'.format(len(adv_x_list)))

    def eval_fgsm_in_validation_set(self, predictions):

        X_test_adv = np.load('src/fgsm/X_adv_out_fgsm.npy')
        Y_test_adv = np.load('src/fgsm/X_adv_out_fgsm.npy')

        eval_params = {'batch_size': self.batch_size}
        accuracy = model_eval(self.session, self.x, self.y, predictions,
                              X_test_adv, Y_test_adv, args=eval_params)

        print('Test accuracy with FGSM adversarial training: {0}'.format(accuracy))

    def calculate_results(self, results, perturbations):
        nb_targets_tried = ((self.classes - 1) * self.attacK_samples)
        succ_rate = float(np.sum(results)) / nb_targets_tried
        print('Avg. rate of successful adv. examples {0:.2f}'.format(succ_rate))

        # Compute the average distortion introduced by the algorithm
        percent_perturbed = np.mean(perturbations)
        print('Avg. rate of perturbed features {0:.2f}'.format(percent_perturbed))

        # Compute the average distortion introduced for successful samples only
        percent_perturb_succ = np.mean(perturbations * (results == 1))
        print('Avg. rate of perturbed features for successful '
              'adversarial examples {0:.2f}'.format(percent_perturb_succ))

    def clean_up(self):
        self.session.close()

if __name__ == "__main__":
    # adv_cnn_jsma = AdversarialCNNJSMA(train_size=500, test_size=100)
    adv_cnn_jsma = AdversarialCNNJSMA(train_size=None, test_size=None)
    # predictions = adv_cnn_jsma.train()

    # Train with adversarial results
    # predictions = adv_cnn_jsma.validate_with_adversarial_fgsm()
    # results, perturbations, adv_x_list, adv_y_list = adv_cnn_jsma.create_adversarial_examples_jsma(predictions)
    # adv_cnn_jsma.calculate_results(results, perturbations)
    # adv_cnn_jsma.eval_fgsm_in_validation_set(predictions)
    adv_cnn_jsma.train_with_adversarial()
    adv_cnn_jsma.clean_up()

